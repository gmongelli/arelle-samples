{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Using Arelle to analyse XBRL ESEF files\n",
    "\n",
    "First of all, we specify which files we want to download from https://filings.xbr.org/ . "
   ],
   "id": "fcfdecf63bb0f4ec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "SAMPLE_URLS = ['https://filings.xbrl.org/222100VRLXV3FPMG4982/2022-12-31/ESEF/LU/0/ESEF_Allegro.eu_Group_Consolidated_Financial_Statements_31.12.2022.zip',\n",
    "                'https://filings.xbrl.org/222100VRLXV3FPMG4982/2023-12-31/ESEF/LU/0/Allegroeu-2023-12-31-en.zip',\n",
    "                'https://filings.xbrl.org/5493008JPA4HYMH1HX51/2022-12-31/ESEF/LU/0/SES%20Annual%20report%20-2022-12-31-en.zip',\n",
    "                'https://filings.xbrl.org/5493008JPA4HYMH1HX51/2023-12-31/ESEF/LU/0/SES_Annual_report_-2023-12-31-en.zip']\n",
    "WORKDIR = os.path.join('..', 'samples')\n",
    "REPORTPACKAGES_DIR = os.path.join(WORKDIR, 'reports')\n",
    "JSON_DATA_DIR = os.path.join(WORKDIR, 'data', 'json')\n",
    "CSV_DATA_DIR = os.path.join(WORKDIR, 'data', 'csv')\n",
    "TABLES_DATA_DIR = os.path.join(WORKDIR, 'data', 'tables')\n",
    "os.makedirs(REPORTPACKAGES_DIR, exist_ok=True)\n",
    "os.makedirs(JSON_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(CSV_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(TABLES_DATA_DIR, exist_ok=True)"
   ],
   "id": "28dcb71aa0eaa3a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We collect the file name from the full URL for each sample file.",
   "id": "f6962999a6af8d54"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import urllib.parse\n",
    "import pathlib\n",
    "\n",
    "sample_filenames:list[list[str, str]] = []\n",
    "for url in SAMPLE_URLS:\n",
    "    parsed_url = urllib.parse.urlparse(url)\n",
    "    filename = pathlib.PurePosixPath(urllib.parse.unquote(parsed_url.path)).parts[-1]\n",
    "    sample_filenames.append([filename, parsed_url.path])\n",
    "print(sample_filenames)"
   ],
   "id": "490f88e173b04551",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Knowing the URL of each file and the final destination dir, we download the files.\n",
    "\n",
    "The final name of the downloaded file is identical with the name specified in the URL."
   ],
   "id": "e509d721cf939751"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import urllib.request\n",
    "\n",
    "def download_file(url, filename) -> str:\n",
    "    download_path = os.path.join(REPORTPACKAGES_DIR, filename)\n",
    "    print(f'Downloading \"{url}\" to\"{download_path}\"')\n",
    "    urllib.request.urlretrieve(url, download_path)\n",
    "    return download_path\n",
    "\n",
    "for i, url in enumerate(SAMPLE_URLS):\n",
    "    sample_filenames[i][1] = download_file(url, sample_filenames[i][0])"
   ],
   "id": "34ddb886a512106",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Finally, we can start using the Arelle API.\n",
    "\n",
    "The API is only in beta stage, it may change in the future.\n",
    "\n",
    "The main principle is to define a `Session` object for which you can specify as many options as you like. They are specified using a `RuntimeOptions` object.\n",
    "\n",
    "The current options are mostly string or booleans.\n",
    "\n",
    "To know which options are available, read the commandline options given in https://arelle.readthedocs.io/en/2.27.5/command_line.html .\n",
    "\n",
    "You may also supply plug-in-specific options. For plug-ins supplied by Arelle itself, you must read the plug-in code to learn which options are available.\n",
    "\n",
    "In the following example, the goal is to generate a OIM-JSON file from an ESEF report package.\n",
    "\n",
    "An ESEF report package is essentially a ZIP archive containing the inline XBRL report alongside an _XBRL taxonomy extension_.\n",
    "\n",
    "The JSON result is extracted as quickly as possible. If during the extraction you want to also validate the whole report package, uncomment the option `validate=True`.\n",
    "\n",
    "**N. B.** If you want to validate an ESEF report package from 2022 backwards, use `disclosureSystemName='esef-2022'`!"
   ],
   "id": "f78c0d2a006a0574"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from arelle.api.Session import Session\n",
    "from arelle.RuntimeOptions import RuntimeOptions\n",
    "\n",
    "def convert_to_oim_json(file_and_path: list[str], targetDir: str) -> str:\n",
    "    json_filename = \".\".join(file_and_path[0].split('.')[:-1 or None]) + '.json'\n",
    "    oim_json_path = os.path.join(targetDir, json_filename)\n",
    "    print(f'JSON converting {file_and_path[0]} to {oim_json_path}')\n",
    "    options = RuntimeOptions(\n",
    "        entrypointFile=str(file_and_path[1]),\n",
    "        disclosureSystemName='esef',\n",
    "        internetConnectivity='online',\n",
    "        keepOpen=False,\n",
    "        logFormat=\"[%(messageCode)s] %(message)s - %(file)s\",\n",
    "        # deduplicateFacts='consistent-pairs',\n",
    "        plugins='validate/ESEF|saveLoadableOIM',\n",
    "        pluginOptions={\n",
    "            'saveLoadableOIM': oim_json_path,\n",
    "        },\n",
    "        strictOptions=False,\n",
    "        # validate=True\n",
    "    )\n",
    "    with Session() as session:\n",
    "        session.run(options)\n",
    "\n",
    "for zip_file in sample_filenames:\n",
    "    convert_to_oim_json(zip_file, JSON_DATA_DIR)"
   ],
   "id": "dda9c2815670f36b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "If you go carefully through the JSON results, you will notice that several facts are duplicated! For a way to deduplicate the facts before generting the JSON file, have a look at https://arelle.readthedocs.io/en/2.27.5/user_guides/fact_deduplication.html .\n",
    "\n",
    "Converting to OIM-CSV is the same code. The only difference is that you specify a target file ending with `.csv`:"
   ],
   "id": "f63e0092377b9930"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from arelle.api.Session import Session\n",
    "from arelle.RuntimeOptions import RuntimeOptions\n",
    "\n",
    "def convert_to_oim_csv(file_and_path: list[str], targetDir: str) -> str:\n",
    "    csv_filename = \".\".join(file_and_path[0].split('.')[:-1 or None]) + '.csv'\n",
    "    oim_csv_path = os.path.join(targetDir, csv_filename)\n",
    "    print(f'CSV converting {file_and_path[0]} to {oim_csv_path}')\n",
    "    options = RuntimeOptions(\n",
    "        entrypointFile=str(file_and_path[1]),\n",
    "        disclosureSystemName='esef',\n",
    "        internetConnectivity='online',\n",
    "        keepOpen=False,\n",
    "        logFormat=\"[%(messageCode)s] %(message)s - %(file)s\",\n",
    "        # deduplicateFacts='consistent-pairs',\n",
    "        plugins='validate/ESEF|saveLoadableOIM',\n",
    "        pluginOptions={\n",
    "            'saveLoadableOIM': oim_csv_path,\n",
    "        },\n",
    "        strictOptions=False,\n",
    "        # validate=True\n",
    "    )\n",
    "    with Session() as session:\n",
    "        session.run(options)\n",
    "\n",
    "for zip_file in sample_filenames:\n",
    "    convert_to_oim_csv(zip_file, CSV_DATA_DIR)"
   ],
   "id": "f3ab2498df8dcb25",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We first open the PostgreSQL database and we create the database tables (only done once).\n",
    "\n",
    "If the database already exists, clear the tables it contains."
   ],
   "id": "dbf811ff276ac70d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pg_db_utils\n",
    "\n",
    "pg_host = 'localhost'\n",
    "pg_port = 5432\n",
    "pg_user = 'xbrl_user'\n",
    "pg_password = 'user123'\n",
    "pg_db = 'xbrl_db'\n",
    "# If your tables do not exist yet, execute:\n",
    "# engine = pg_db_utils.init_DB(pg_user, pg_password, pg_host, pg_port, pg_db)\n",
    "engine = pg_db_utils.connect_DB(pg_user, pg_password, pg_host, pg_port, pg_db)\n",
    "DB_session = pg_db_utils.session_factory(engine)\n",
    "pg_db_utils.delete_all(DB_session)"
   ],
   "id": "710cb83a47375f78",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Use Arelle to open the sample reports, to iterate through all facts and to save them to the database.",
   "id": "31e819490af12cba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from arelle.api.Session import Session\n",
    "from arelle.ModelInstanceObject import ModelContext\n",
    "from arelle.RuntimeOptions import RuntimeOptions\n",
    "from arelle.ValidateXbrlCalcs import inferredDecimals\n",
    "from pg_db_utils import insert_document, insert_fact\n",
    "\n",
    "def add_dimensions(context: ModelContext) -> dict[str, str] :\n",
    "    dimensions_dict: dict[str, str] = {}\n",
    "    for _qn, dim in sorted(context.qnameDims.items(), key=lambda item: item[0]):\n",
    "        if dim.isExplicit:\n",
    "            dim_value = dim.memberQname.clarkNotation\n",
    "        else: # typed dimension\n",
    "            if dim.typedMember.get(\"{http://www.w3.org/2001/XMLSchema-instance}nil\") in (\"true\", \"1\"):\n",
    "                dim_value = None\n",
    "            else:\n",
    "                dim_value = dim.typedMember.stringValue\n",
    "        dim_name = dim.dimensionQname.clarkNotation\n",
    "        dimensions_dict[dim_name] = dim_value\n",
    "    return dimensions_dict\n",
    "\n",
    "def extract_data(file_and_path: list[str], target_dir: str) -> str:\n",
    "    table_files_dir = \".\".join(file_and_path[0].split('.')[:-1 or None]) + '_'\n",
    "    table_files_path = os.path.join(target_dir, table_files_dir)\n",
    "    print(f'Extracting data from {file_and_path[0]} to database and directory {table_files_path}')\n",
    "    document_id = insert_document(DB_session, file_and_path[0])\n",
    "    options = RuntimeOptions(\n",
    "        entrypointFile=str(file_and_path[1]),\n",
    "        disclosureSystemName='esef',\n",
    "        internetConnectivity='online',\n",
    "        keepOpen=True,\n",
    "        logFormat=\"[%(messageCode)s] %(message)s - %(file)s\",\n",
    "        # deduplicateFacts='consistent-pairs',\n",
    "        plugins='validate/ESEF',\n",
    "        strictOptions=False,\n",
    "        # validate=True\n",
    "    )\n",
    "    os.makedirs(table_files_path, exist_ok=True)\n",
    "    with Session() as session:\n",
    "        session.run(options)\n",
    "        model_xbrls = session.get_models()\n",
    "        for model_xbrl in model_xbrls:\n",
    "            facts = model_xbrl.facts\n",
    "            for fact in facts:\n",
    "                concept = fact.concept\n",
    "                concept_full_name = concept.qname.clarkNotation\n",
    "                context = fact.context\n",
    "                entity = context.entity.stringValue\n",
    "                if context.isInstantPeriod:\n",
    "                    period_start = None\n",
    "                    period_end = context.instantDatetime\n",
    "                elif context.isStartEndPeriod:\n",
    "                    period_start = context.startDatetime\n",
    "                    period_end = context.endDatetime\n",
    "                else: # forever period\n",
    "                    period_start = period_end = None\n",
    "                all_dimensions = add_dimensions(context)\n",
    "                value = fact.value\n",
    "                decimals = inferredDecimals(fact)\n",
    "                unit_as_string = None\n",
    "                if fact.unit:\n",
    "                    unit_as_string = fact.unit.value\n",
    "                language = 'en'\n",
    "                insert_fact(DB_session,\n",
    "                            document_id,\n",
    "                            value,\n",
    "                            decimals,\n",
    "                            concept_full_name,\n",
    "                            entity,\n",
    "                            period_start,\n",
    "                            period_end,\n",
    "                            unit_as_string,\n",
    "                            language,\n",
    "                            all_dimensions)\n",
    "            model_xbrl.close()\n",
    "\n",
    "for zip_file in sample_filenames:\n",
    "    extract_data(zip_file, TABLES_DATA_DIR)"
   ],
   "id": "669b40576fa44537",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We have now everything we need to work with the fact.\n",
    "\n",
    "However, the `ModelXbrl` objects also capture most of the content of the XBRL taxonomies. One of the more current needs is to extract the labels associated to a concept.\n",
    "\n",
    "Arelle offers for that purpose the method `arelle.ModelDtsObject.ModelConcept.label`. We shall load one of the sample documents and extract all the labels associated to the concept `ifrs-full:ProfitLoss` (in prefix notation). "
   ],
   "id": "3fbc6065c3b03640"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from arelle.api.Session import Session\n",
    "from arelle.RuntimeOptions import RuntimeOptions\n",
    "from arelle.ModelValue import QName\n",
    "\n",
    "sample_file_to_analyse = sample_filenames[3]\n",
    "concept_qname_to_analyse = QName(\"ifrs-full\", \"https://xbrl.ifrs.org/taxonomy/2022-03-24/ifrs-full\", \"ProfitLoss\")\n",
    "\n",
    "print(f\"Display all labels of concept {concept_qname_to_analyse} from {sample_file_to_analyse}\")\n",
    "\n",
    "options = RuntimeOptions(\n",
    "        entrypointFile=str(sample_file_to_analyse[1]),\n",
    "        disclosureSystemName='esef',\n",
    "        internetConnectivity='online',\n",
    "        keepOpen=True,\n",
    "        logFormat=\"[%(messageCode)s] %(message)s - %(file)s\",\n",
    "        plugins='validate/ESEF',\n",
    "        strictOptions=False\n",
    "    )\n",
    "with Session() as session:\n",
    "    session.run(options)\n",
    "    model_xbrls = session.get_models()\n",
    "    for model_xbrl in model_xbrls:\n",
    "        try:\n",
    "            concept = model_xbrl.qnameConcepts[concept_qname_to_analyse]\n",
    "            print('Standard label in English (the standard label is the default if the parameter \"preferredLabel\" is not specified): \"' + concept.label(lang='en') + '\"')\n",
    "            print('Standard label in French (does not exist, concept name is returned instead): \"' + concept.label(lang='fr') + '\"')\n",
    "            print('Total label in English: \"' + concept.label(preferredLabel='http://www.xbrl.org/2003/role/totalLabel', lang=('en', 'fr')) + '\"')\n",
    "        except KeyError:\n",
    "            continue\n",
    "        model_xbrl.close()"
   ],
   "id": "84bdf601eed208b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Notice that a label can be present in multiple languages. Always specify the language you are interested in by specifying the parameter `lang` of method `label`. You may either specify a string or a list of strings.\n",
    "\n",
    "Do not hesitate to look at `arelle/ModelDtsObject.py` in the source code of Arelle to check the usage of the other named parameters."
   ],
   "id": "aa611de7bd34869c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
